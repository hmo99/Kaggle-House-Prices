{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('train.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as sns\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "def data_process(df_raw,remove_outlier = False,remove_hard_to_fit = False,linear_model = False, get_dummies=False, label_encode=False ):\n",
    "\n",
    "\t# Make a copy so the original dataframe will not be altered.\n",
    "    df_processed = df_raw.copy()\n",
    "    \n",
    "    \n",
    "\t# Remove outliers.\n",
    "    outlier_list = [524, 1299, 463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424]\n",
    "    df_processed = df_processed.drop(outlier_list)\n",
    "\n",
    "    \n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "    df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "    df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "    df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "    df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with Nb\n",
    "    df_processed.BsmtQual = df_processed.BsmtQual.fillna('Nb')\n",
    "    df_processed.BsmtCond = df_processed.BsmtCond.fillna('Nb')\n",
    "    df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('Nb')\n",
    "    df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('Nb')\n",
    "    df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('Nb')\n",
    "    df_processed.TotalBsmtSF = df_processed.TotalBsmtSF.fillna(0)\n",
    "    \n",
    "\n",
    "    # 690 FireplaceQu - replace with Nf\n",
    "    df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('Nf')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with Ng and year with 0 \n",
    "    df_processed.GarageType = df_processed.GarageType.fillna('Ng')\n",
    "    df_processed.GarageFinish = df_processed.GarageFinish.fillna('Ng')\n",
    "    df_processed.GarageQual = df_processed.GarageQual.fillna('Ng')\n",
    "    df_processed.GarageCond = df_processed.GarageCond.fillna('Ng')\n",
    "    df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with Np\n",
    "    df_processed.PoolQC = df_processed.PoolQC.fillna('Np')\n",
    "\n",
    "    # 1179 Fence - replace with Nf\n",
    "    df_processed.Fence = df_processed.Fence.fillna('Nf')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "    df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "    df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "\n",
    "    ## Combine columns and drop multicollinear columns \n",
    "    \n",
    "    # combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "\n",
    "    # drop TotalBsmtSF - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['TotalBsmtSF'], axis=1)\n",
    "\n",
    "    # drop GrLivArea - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['GrLivArea'], axis=1)\n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    \n",
    "    \n",
    "\t# Feature Transformation - take the logarithm of the features.\n",
    "    #Linear_Num_Cols = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'GarageArea', 'TotRmsAbvGrd', 'TotalSF', 'BsmtFinSF1']\n",
    "    df_processed.SalePrice = np.log(df_processed.SalePrice)\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    df_processed.TotalBsmtSF = np.log(df_processed.TotalBsmtSF+1)\n",
    "#     df_processed.LotArea = np.log(df_processed.LotArea) -- performance decreases\n",
    "#     df_processed.GarageArea = np.log(df_processed.GarageArea)\n",
    "\n",
    "\n",
    "\n",
    "\t# Categorical Features Processsing\n",
    "\n",
    "\t# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    df_processed[['MSSubClass','OverallQual','OverallCond']] = df_processed[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "\n",
    "    #Get Dummies \n",
    "    \n",
    "    if get_dummies:\n",
    "        df_processed = pd.get_dummies(df_processed, columns=df_processed.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "    \n",
    "    \n",
    "    #get label encoder. categorical data change to numerical values\n",
    "    if label_encode:\n",
    "        le = LabelEncoder()\n",
    "        categorical_ordinal_col=df_processed.select_dtypes(include=['object']).columns.to_list()\n",
    "        df_processed[categorical_ordinal_col]=df_processed[categorical_ordinal_col].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "   #---Multiply features: \n",
    "#     df_processed[\"add_OverallGrade\"] = df_processed[\"OverallQual\"] * df_processed[\"OverallCond\"]\n",
    "#     df_processed[\"add_GarageGrade\"] = df_processed[\"GarageQual\"] * df_processed[\"GarageCond\"]\n",
    "#     df_processed[\"add_ExterGrade\"] = df_processed[\"ExterQual\"] * df_processed[\"ExterCond\"]\n",
    "#     df_processed[\"add_KitchenScore\"] = df_processed[\"KitchenAbvGr\"] * df_processed[\"KitchenQual\"]\n",
    "#     df_processed[\"add_FireplaceScore\"] = df_processed[\"Fireplaces\"] * df_processed[\"FireplaceQu\"]\n",
    "#     df_processed[\"add_GarageScore\"] = df_processed[\"GarageArea\"] * df_processed[\"GarageQual\"]\n",
    "#     df_processed[\"add_PoolScore\"] = df_processed[\"PoolArea\"] * df_processed[\"PoolQC\"]\n",
    "#     df_processed['add_GrLivArea*OvQual'] = df_processed['GrLivArea'] * df_processed['OverallQual']\n",
    "#     df_processed['add_QualOverall*Exter*Kitch*Bsmt*Garage'] = df_processed['OverallQual'] * df_processed['ExterQual'] * df_processed['KitchenQual'] * df_processed['BsmtQual'] * df_processed['GarageQual']\n",
    "\n",
    "\n",
    "\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_ordinal_col=['Alley',\n",
    "#  'BldgType',\n",
    "#  'BsmtCond',\n",
    "#  'BsmtExposure',\n",
    "#  'BsmtFinType1',\n",
    "#  'BsmtFinType2',\n",
    "#  'BsmtQual',\n",
    "#  'CentralAir',\n",
    "#  'Condition1',\n",
    "#  'Condition2',\n",
    "#  'Electrical',\n",
    "#  'ExterCond',\n",
    "#  'ExterQual',\n",
    "#  'Exterior1st',\n",
    "#  'Exterior2nd',\n",
    "#  'Fence',\n",
    "#  'FireplaceQu',\n",
    "#  'Foundation',\n",
    "#  'Functional',\n",
    "#  'GarageCond',\n",
    "#  'GarageFinish',\n",
    "#  'GarageQual',\n",
    "#  'GarageType',\n",
    "#  'Heating',\n",
    "#  'HeatingQC',\n",
    "#  'HouseStyle',\n",
    "#  'KitchenQual',\n",
    "#  'LandContour',\n",
    "#  'LandSlope',\n",
    "#  'LotConfig',\n",
    "#  'LotShape',\n",
    "#  'MSSubClass',\n",
    "#  'MSZoning',\n",
    "#  'MasVnrType',\n",
    "#  'MiscFeature',\n",
    "#  'Neighborhood',\n",
    "#  'OverallCond',\n",
    "#  'OverallQual',\n",
    "#  'PavedDrive',\n",
    "#  'PoolQC',\n",
    "#  'RoofMatl',\n",
    "#  'RoofStyle',\n",
    "#  'SaleCondition',\n",
    "#  'SaleType',\n",
    "#  'Street',\n",
    "#  'Utilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #List of numerical columns\n",
    "# numerical_col=['LotFrontage',\n",
    "#  'LotArea',\n",
    "#  'YearBuilt',\n",
    "#  'YearRemodAdd',\n",
    "#  'MasVnrArea',\n",
    "#  'BsmtFinSF1',\n",
    "#  'BsmtFinSF2',\n",
    "#  'BsmtUnfSF',\n",
    "#  '1stFlrSF',\n",
    "#  '2ndFlrSF',\n",
    "#  'LowQualFinSF',\n",
    "#  'BedroomAbvGr',\n",
    "#  'KitchenAbvGr',\n",
    "#  'TotRmsAbvGrd',\n",
    "#  'Fireplaces',\n",
    "#  'GarageYrBlt',\n",
    "#  'GarageCars',\n",
    "#  'WoodDeckSF',\n",
    "#  'OpenPorchSF',\n",
    "#  'EnclosedPorch',\n",
    "#  '3SsnPorch',\n",
    "#  'ScreenPorch',\n",
    "#  'PoolArea',\n",
    "#  'MiscVal',\n",
    "#  'MoSold',\n",
    "#  'YrSold',\n",
    "#  'SalePrice',\n",
    "#  'BsmtBath',\n",
    "#  'Bath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_process() got an unexpected keyword argument 'label_encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-abdb2a551c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#data prep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_processed_label_encode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_encode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_processed_label_encode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data_process() got an unexpected keyword argument 'label_encode'"
     ]
    }
   ],
   "source": [
    "#data prep\n",
    "data_processed_label_encode=data_process(df_raw,label_encode=True)\n",
    "data_processed_label_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "    \n",
    "\n",
    "def model_random_forest_sklearn(data_processed, \n",
    "                                n_estimators,\n",
    "                                max_features,\n",
    "                                max_depth):\n",
    "    \n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data_processed)\n",
    "\n",
    "    # The predicted column is \"SalePrice\" .\n",
    "    train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "    test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "    train_y = train[[\"SalePrice\"]]\n",
    "    test_y = test[[\"SalePrice\"]]\n",
    " \n",
    " #The number of jobs to run in parallel for both fit and predict.\n",
    "    rfr = RandomForestRegressor(n_jobs=1, random_state=0, oob_score=True)\n",
    "    param_grid = {'n_estimators': n_estimators, # number of trees\n",
    "                  'max_features': max_features, #The number of features to consider when looking for the best split\n",
    "                  'max_depth':max_depth} #max depth of the tree\n",
    "    \n",
    "    model = GridSearchCV(estimator=rfr, param_grid=param_grid, n_jobs=1,cv=5)\n",
    "    model.fit(train_x, train_y.values.ravel())\n",
    "    \n",
    "    print('Random forecast regression...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "    \n",
    "    #Mean cross-validated score of the best_estimator\n",
    "    print('Best CV Score:') \n",
    "    print(model.best_score_)\n",
    "    \n",
    "    y_pred = model.predict(test_x)\n",
    "    print ('test model r2:',model.score(test_x,test_y))\n",
    "    print ('train model r2:', model.score(train_x, train_y))\n",
    "    \n",
    "    #eval_metrics(actual, predicted)\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, y_pred)\n",
    "    \n",
    "   # print ('oob score:', model.oob_score_ )\n",
    "    \n",
    "    # Print out metrics\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "    \n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    mlflow.log_param(\"max_depth\", model.best_params_.get('max_depth'))\n",
    "    mlflow.log_param(\"max_features\", model.best_params_.get('max_features'))\n",
    "    mlflow.log_param(\"n_estimators\", model.best_params_.get('n_estimators'))\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    #mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    mlflow.sklearn.log_model(rfr, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forecast regression...\n",
      "Best Params:\n",
      "{'max_depth': 20, 'max_features': 10, 'n_estimators': 100}\n",
      "Best CV Score:\n",
      "0.829757167561785\n",
      "test model r2: 0.8137184741407288\n",
      "train model r2: 0.9756807061139423\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'oob_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-146411879381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#                                 max_features,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#                                 max_depth):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_random_forest_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_processed_with_dummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-294225ad6ff9>\u001b[0m in \u001b[0;36mmodel_random_forest_sklearn\u001b[1;34m(data_processed, n_estimators, max_features, max_depth)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'oob score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Print out metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'oob_score_'"
     ]
    }
   ],
   "source": [
    "#Run random forest\n",
    "\n",
    "# def model_random_forest_sklearn(data_processed, \n",
    "#                                 n_estimators,\n",
    "#                                 max_features,\n",
    "#                                 max_depth):\n",
    "model_random_forest_sklearn(data_processed_label_encode, [100],[5,8,10], [20,25,10,5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forecast regression...\n",
      "Best Params:\n",
      "{'max_depth': 25, 'max_features': 10, 'n_estimators': 100}\n",
      "Best CV Score:\n",
      "0.8582240300622415\n",
      "test model r2: 0.8548783370637293\n",
      "train model r2: 0.9802158088439499\n",
      "  RMSE: 0.14927884894154003\n",
      "  MAE: 0.10084586789784643\n",
      "  R2: 0.8548783370637294\n"
     ]
    }
   ],
   "source": [
    "#Run random forest\n",
    "\n",
    "# def model_random_forest_sklearn(data_processed, \n",
    "#                                 n_estimators,\n",
    "#                                 max_features,\n",
    "#                                 max_depth):\n",
    "model_random_forest_sklearn(data_processed_label_encode,[100],[5,8,10], [20,25,10,5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  9.2min finished\n",
      "C:\\Users\\Laptop2\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:714: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "  \n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data_processed_label_encode)\n",
    "\n",
    "# The predicted column is \"SalePrice\" .\n",
    "train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "train_y = train[[\"SalePrice\"]]\n",
    "test_y = test[[\"SalePrice\"]]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(train_x, train_y)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2880 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8640 out of 8640 | elapsed: 45.7min finished\n",
      "C:\\Users\\Laptop2\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:714: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 9,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 396}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [None],\n",
    "    'max_features': [6,7,8,9],\n",
    "    'min_samples_leaf': [1,2,3,4],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'n_estimators': list(range(390,450))\n",
    "}# Create a based model\n",
    "rf = RandomForestRegressor()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_x, train_y)\n",
    "grid_search.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean cross-validated score of the best_estimator\n",
    "print('Best CV Score:') \n",
    "print(grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(test_x)\n",
    "print ('test model r2:',grid_search.score(test_x,test_y))\n",
    "print ('train model r2:', grid_search.score(train_x, train_y))\n",
    "    \n",
    "#eval_metrics(actual, predicted)\n",
    "(rmse, mae, r2) = eval_metrics(test_y, y_pred)\n",
    "\n",
    "print ('oob score:', grid_search.oob_score_ )\n",
    "\n",
    "# Print out metrics\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
